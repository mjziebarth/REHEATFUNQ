{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e9ea4b",
   "metadata": {},
   "source": [
    "# 3. Parameter Estimation for the Gamma Conjugate Prior\n",
    "In this notebook, parameters for the gamma conjugate prior (GCP) are estimated using the\n",
    "*least surprise estimate*, that is, by minimizing the maximum Kullback-Leibler distance\n",
    "of the GCP to any of the regional distributions.\n",
    "\n",
    "\n",
    "## Configuration\n",
    "First, the configuration of the fitting algorithm. As described in the REHEATFUNQ model\n",
    "description paper, the algorithm proceeds by randomly distributing disks across a spherical\n",
    "Earth, and for each disk selecting data from the filtered global heat flow database that\n",
    "are within the disk. The following parameters control the disk size and the disk acceptance\n",
    "criterion:\n",
    "\n",
    "| Parameter    | Purpose                                                                                       |\n",
    "| :---------   | :-------------------------------------------------------------------------------------------- |\n",
    "| `R`          | Radius of the disks, in meters.                                                               |\n",
    "| `DMIN_KM`    | Minimum distance between two data points in km. Select one of each violating pair at random.  |\n",
    "| `min_points` | Minimum number of selected points. Reject proposed disks if less selected points within.      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 80e3\n",
    "DMIN_KM = 20\n",
    "min_points = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db30bafe",
   "metadata": {},
   "source": [
    "## Package imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Proj\n",
    "from pathlib import Path\n",
    "from zeal2022hf import kindlmann, kindlmann_r\n",
    "from loaducerf3 import PolygonSelector, Polygon\n",
    "from pdtoolbox.distributions import *\n",
    "from pdtoolbox.mle import *\n",
    "from pdtoolbox.likelihood import *\n",
    "from pickle import Pickler, Unpickler\n",
    "from cache import cached_call\n",
    "from reheatfunq.coverings import random_global_R_disk_coverings\n",
    "from reheatfunq import GammaConjugatePrior\n",
    "from reheatfunq.regional.backend import gamma_mle\n",
    "from cmcrameri.cm import *\n",
    "from matplotlib.patches import Polygon as MPolygon\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fcfe2",
   "metadata": {},
   "source": [
    "Figure style configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c0328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams[\"text.usetex\"] = False\n",
    "rcParams['font.family'] = 'sans'\n",
    "rcParams['text.latex.preamble'] = \"\\\\renewcommand{\\\\familydefault}{\\\\sfdefault}\\n\\\\usepackage{helvet}\"\n",
    "rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d109554",
   "metadata": {},
   "source": [
    "Configure plots to look good on a HiDPI monitor (you may not need the following configuration if you are not using a HiDPI monitor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceecbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9dafd2",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Load the data set processed in `01-Load-and-filter-NGHF.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_continental = np.load('intermediate/heat-flow-selection-mW_m2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681887a5",
   "metadata": {},
   "source": [
    "### Exclude areas used in regional analyses\n",
    "Load the selectors that will later select the regional aggregate heat flow distributions.\n",
    "These polygon selectors have been defined in `02-Study-Area-Geometry.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829517e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intermediate/02-Geometry.pickle','rb') as f:\n",
    "    saf_geometry = Unpickler(f).load()\n",
    "\n",
    "proj_saf = Proj(saf_geometry[\"proj_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(hf_continental.shape[1], dtype=bool)\n",
    "hf_xy = np.stack(proj_saf(*hf_continental[1:3,:]), axis=1)\n",
    "\n",
    "for poly in saf_geometry[\"selection_polygons_xy\"]:\n",
    "    select = PolygonSelector(Polygon(*poly[:-1].T))\n",
    "    mask &= ~select.array_mask(hf_xy)\n",
    "hf_independent = (hf_continental.T)[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e66ce",
   "metadata": {},
   "source": [
    "### Back-indexing to the NGHF data set\n",
    "Compute the indices of the masked data within the original NGHF data set (Lucazeau, 2019)\n",
    "for simple reproducibility. This might or might not be relevant for applications to other\n",
    "areas and/or data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_continental_indices = np.loadtxt('results/nghf-selection-indices.csv', delimiter=',', dtype=int)\n",
    "\n",
    "# We also have to update the indices into hf_continental now:\n",
    "local2continental = np.arange(mask.size)[mask]\n",
    "local2lucazeau = hf_continental_indices[local2continental]\n",
    "lucazeau2local = {i : j for i,j in enumerate(local2lucazeau)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a603c76",
   "metadata": {},
   "source": [
    "### Create a disk-buffer around the polygons\n",
    "In the later analysis based on the random distribution of disks all over\n",
    "Earth surface, we want to prevent the disks from overlapping with the selection\n",
    "polygons. Using the buffer functionality of Shapely, we can create buffered\n",
    "polygons (buffer by disk radius) that can prevent by rejecting any disk center\n",
    "whose center is within the buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5aff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 80e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52affa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect('equal')\n",
    "buffered_shpoly = shapely.geometry.Polygon()\n",
    "for poly in saf_geometry[\"selection_polygons_xy\"]:\n",
    "    ax.plot(*poly.T, color='k')\n",
    "    shpoly = shapely.geometry.Polygon(poly).buffer(R)\n",
    "    buffered_shpoly = buffered_shpoly.union(shpoly)\n",
    "\n",
    "x,y = buffered_shpoly.exterior.coords.xy\n",
    "ax.plot(x,y,color='gray')\n",
    "buffered_poly = np.array(x[:-1]), np.array(y[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intermediate/03-Buffered-Poly.pickle','wb') as f:\n",
    "    Pickler(f).dump(buffered_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf699a2",
   "metadata": {},
   "source": [
    "## Determine Regional Distributions\n",
    "First off, prepare some code for spatial filtering. So far, we have not checked for double entries to the data base. Also, we might want to remove data points that are too close to each other (circumventing the spatial clustering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 498267187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e04ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_points, used_data_entries, distributions, distribution_lola, distribution_indices \\\n",
    "    = cached_call(random_global_R_disk_coverings, R, min_points,\n",
    "                  hf_independent, buffered_poly, saf_geometry[\"proj_str\"], dmin=DMIN_KM*1e3,\n",
    "                  MAX_DRAW=10000000, N=200, seed=seed)\n",
    "\n",
    "print(\"Number of distributions:  \",len(distributions))\n",
    "print(\"Maximum distribution size:\", max(d.size for d in distributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485871a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "# Histogram of sample size:\n",
    "ax = fig.add_subplot(131)\n",
    "ax.hist([d.size for d in distributions], bins=20)\n",
    "ax.set_xlabel('Regional sample size')\n",
    "ax.set_ylabel('Number of regions')\n",
    "\n",
    "# Global distribution:\n",
    "ax = fig.add_subplot(132)\n",
    "ax.scatter(*hf_independent[:,1:3].T, marker='.', edgecolor='none')\n",
    "ax.scatter(*np.array(valid_points).T, marker='x')\n",
    "ax.plot(*proj_saf(x, y, inverse=True), color='gray')\n",
    "\n",
    "# The study area:\n",
    "ax = fig.add_subplot(133)\n",
    "ax.plot(*proj_saf(x, y, inverse=True), color='gray')\n",
    "ax.set_xlim(ax.get_xlim())\n",
    "ax.set_ylim(ax.get_ylim())\n",
    "ax.scatter(*hf_independent[:,1:3].T, marker='.', edgecolor='none')\n",
    "ax.scatter(*np.array(valid_points).T, marker='x')\n",
    "\n",
    "\n",
    "Path('figures').mkdir(exist_ok=True)\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/03-RGRDC-sample-sizes-and-locations.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a186437",
   "metadata": {},
   "source": [
    "Mark the data entries that will be used in the later regional analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "ude = []\n",
    "for i,d in enumerate(distributions):\n",
    "    Ni = d.size\n",
    "    ude.append([int(local2lucazeau[k])\n",
    "                for k in used_data_entries[j:j+Ni]])\n",
    "    j += Ni\n",
    "\n",
    "used_data_entries = ude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e719b",
   "metadata": {},
   "source": [
    "Maximum-likelihood estimates to the regional distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a473615",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = np.array([gamma_mle(dist, amin=1.0) for dist in distributions]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c0ac7",
   "metadata": {},
   "source": [
    "Export the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de684a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('results').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8425321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results/03-gamma-conjugate-prior-results.json','w') as f:\n",
    "    json.dump([(pts, entries, (a,b))\n",
    "               for pts, entries, a, b in zip(valid_points, used_data_entries, A, B)],\n",
    "              f)\n",
    "pts_feature_list = [{\"type\" : \"Feature\",\n",
    "                     \"geometry\" : {\n",
    "                         \"type\" : \"Point\",\n",
    "                         \"coordinates\" : pt,\n",
    "                     },\n",
    "                     \"properties\" : {\n",
    "                         \"a\" : a,\n",
    "                         \"b\" : b,\n",
    "                         \"lucazeau2019entries\" : entries\n",
    "                     }} for pt, entries, a, b in zip(valid_points, used_data_entries, A, B)]\n",
    "geojson_dict = { \"type\": \"FeatureCollection\",\n",
    "                 \"name\" : \"Ziebarth et al. (2021) gamma distribution fits to Lucazeau (2019) heat flow data\",\n",
    "                 \"license\" : \"CC-BY 4.0\",\n",
    "                 \"features\": pts_feature_list}\n",
    "with open('results/gamma-conjugate-prior-results.geojson','w') as f:\n",
    "    json.dump(geojson_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639807a5",
   "metadata": {},
   "source": [
    "## Fit the Gamma Conjugate Prior\n",
    "We compute the *minimum surprise estimate* (MSE) of the gamma conjugate prior given the distributions.\n",
    "The MSE minimizes the Kullback-Leibler (KL) distance between conjugate prior $\\phi(\\alpha,\\beta)$ and\n",
    "the heat flow data.\n",
    "In particular, for each aggregate heat flow distribution $Q_i = \\{q_j\\}_i$, a posterior probability\n",
    "$\\pi_i(\\alpha, \\beta)$ is computed from an \"uninformed\" prior ($p_i=1$, $s_i=n_i=v_i=0$, see Miller, 1980).\n",
    "Then, the maximum KL distance $d$ from the conjugate prior to any of the $\\pi_i$,\n",
    "$$\n",
    "    d = \\max\\limits_i \\left\\{ \\,\\int\\limits_{\\alpha_\\mathrm{min}}^\\infty\\!\\mathrm{d}\\alpha\n",
    "                              \\int\\limits_{0}^\\infty\\!\\mathrm{d}\\beta \\,\n",
    "                              \\pi_i(\\alpha,\\beta)\n",
    "                              \\ln\\left(\\frac{\\pi_i(\\alpha,\\beta)}{\\phi(\\alpha,\\beta)}\\right)     \n",
    "                      \\right\\}\n",
    "$$\n",
    "is minimized using the SciPy L-BFGS-B optimizer to yield the parameter estimates $\\hat{p}$, $\\hat{s}$,\n",
    "$\\hat{n}$, $\\hat{\\nu}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4adf55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp = GammaConjugatePrior.minimum_surprise_estimate(distributions, verbose=True)\n",
    "gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72bed7",
   "metadata": {},
   "source": [
    "##### Inspect the results\n",
    "\n",
    "Plot the cost function surrounding the minimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4649cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_i = [GammaConjugatePrior(1, 0, 0, 0).updated(dist) for dist in distributions]\n",
    "\n",
    "def cost_function(p, s, n, v):\n",
    "    try:\n",
    "        gcp = GammaConjugatePrior(p, s, n, v)\n",
    "        return max(gcp.kullback_leibler(gcpi) for gcpi in GCP_i)\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ad685",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.linspace(np.exp(gcp.lp)-0.01, np.exp(gcp.lp)+0.01, M+1)\n",
    "S = np.linspace(gcp.s-0.05, gcp.s+0.05, M)\n",
    "C = np.array([[cost_function(p, s, gcp.n, gcp.v) for p in P] for s in S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.linspace(gcp.n-0.01, gcp.n+0.01, M+1)\n",
    "V = np.linspace(gcp.v-0.01, gcp.v+0.01, M)\n",
    "C2 = np.array([[cost_function(np.exp(gcp.lp), gcp.s, n, v)\n",
    "               if (n > v and n-v < 0.008) else np.NaN for n in N] for v in V])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"font.size\" : 10, \"xtick.labelsize\" : \"small\", \"ytick.labelsize\" : \"small\"}):\n",
    "    fig = plt.figure(figsize=(6.975, 4.0))\n",
    "    #ax_bg = fig.add_axes((0,0,1,1))\n",
    "    cax = fig.add_axes((0.33, 0.11, 0.34, 0.02))\n",
    "    ax = fig.add_axes((0.09, 0.28, 0.38, 0.71))\n",
    "    Cmax = 10.0\n",
    "    mask = C < Cmax\n",
    "    Cp = C.copy()\n",
    "    Cp[~mask] = np.NaN\n",
    "    mask = C2 < Cmax\n",
    "    Cp2 = C2.copy()\n",
    "    Cp2[~mask] = np.NaN\n",
    "    norm = Normalize(min(Cp[mask].min(),Cp2[mask].min()), Cmax)\n",
    "    h = ax.pcolormesh(P, S, Cp, norm=norm, cmap=batlow, rasterized=True)\n",
    "    ax.scatter(np.exp(gcp.lp), gcp.s, marker='h', facecolor='w', edgecolor='k', linewidth=0.8,\n",
    "               label='Optimum')\n",
    "    ax.set_xlabel('$p$')\n",
    "    ax.set_ylabel('$s$');\n",
    "    for tick in ax.get_yticklabels():\n",
    "        tick.set_rotation(45)\n",
    "    ax = fig.add_axes((0.59, 0.28, 0.38, 0.71))\n",
    "    h = ax.pcolormesh(N, V, Cp2, norm=norm, cmap=batlow, rasterized=True)\n",
    "    ax.scatter(gcp.n, gcp.v, marker='h', facecolor='w', edgecolor='k', linewidth=0.8,\n",
    "               label='Optimum')\n",
    "    ax.legend()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.set_xlim((min(xlim[0],ylim[0]), max(xlim[1],ylim[1])))\n",
    "    ax.set_ylim((min(xlim[0],ylim[0]), max(xlim[1],ylim[1])))\n",
    "    ax.add_patch(MPolygon([(xlim[0],ylim[0]), (xlim[1],ylim[1]), (xlim[0], ylim[1])], color='lightgray',zorder=0))\n",
    "    fig.colorbar(h, cax=cax, orientation='horizontal', extend='max')\n",
    "    cax.set_xlabel('Cost function')\n",
    "    ax.set_xlabel('$n$')\n",
    "    ax.set_ylabel('$\\\\nu$');\n",
    "    for tick in ax.get_yticklabels():\n",
    "        tick.set_rotation(45);\n",
    "    \n",
    "    fig.savefig('figures/03-Optimization-Result-psnv.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctmp = C.copy()\n",
    "Ctmp[np.isnan(Ctmp)] = np.inf\n",
    "print(\"final:      \",cost_function(np.exp(gcp.lp), gcp.s, gcp.n, gcp.v))\n",
    "print(\"raster best:\",Ctmp.min())\n",
    "imin, jmin = np.unravel_index(np.argmin(Ctmp), Ctmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce7d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctmp = C2.copy()\n",
    "Ctmp[np.isnan(Ctmp)] = np.inf\n",
    "print(\"final:      \",cost_function(np.exp(gcp.lp), gcp.s, gcp.n, gcp.v))\n",
    "print(\"raster best:\",Ctmp.min())\n",
    "kmin, lmin = np.unravel_index(np.argmin(Ctmp), Ctmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0387f",
   "metadata": {},
   "source": [
    "Plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "gcp.visualize(ax, distributions, cmap=kindlmann_r,\n",
    "              q_plot = [(25., 1.0, 50.0, 'lightgray'), (130., 10.0, 1000, 'lightgray')],\n",
    "              qstd_plot = [2.2, (60., 1.1, 50, 'w')])\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/03-Gamma-Conjugate-Prior.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ac853",
   "metadata": {},
   "source": [
    "Prior predictive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "QMAX = 250\n",
    "q = np.linspace(0, QMAX, 500)\n",
    "pdf = gcp.posterior_predictive(q)\n",
    "cdf = gcp.posterior_predictive_cdf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6efb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tail >= 250 mWm²:\",100 * (1.0 - cdf[-1]),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea566d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.linspace(0, 1, 200)\n",
    "empirical_cdf_exceedance = np.zeros((z.size, q.size, len(distributions)))\n",
    "cdf_discrete = np.zeros_like(q)\n",
    "for i,dist in enumerate(distributions):\n",
    "    cdf_discrete[:] = 0.0\n",
    "    for qi in dist:\n",
    "        cdf_discrete[q >= qi] += 1.0\n",
    "    cdf_discrete /= dist.size\n",
    "    for j in range(q.size):\n",
    "        empirical_cdf_exceedance[z <= cdf_discrete[j], j, i] = 1\n",
    "\n",
    "empirical_cdf_exceedance = empirical_cdf_exceedance.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6.975, 2.6))\n",
    "ax = fig.add_axes((0.08, 0.175, 0.36, 0.80))\n",
    "ax.plot(q, 100*pdf, label='Prior predictive\\nPDF')\n",
    "ax.set_ylim(0, 2.55)\n",
    "ax.set_xlim(0,QMAX)\n",
    "ax.set_xlabel('Heat flow $q$ ($\\mathrm{mWm}^{-2}$)')\n",
    "ax.set_ylabel('PDF ($10^2\\,\\\\mathrm{mW}^{-1}\\\\mathrm{m}^2$)')\n",
    "ax.axvline(68.3, linewidth=0.8, linestyle='--', color='k',\n",
    "           label='$68.3\\,\\mathrm{mWm}^{-2}$')\n",
    "ax.legend(fontsize='small')\n",
    "ax = fig.add_axes((0.53, 0.175, 0.36, 0.80))\n",
    "cax = fig.add_axes((0.9, 0.3, 0.02, 0.6))\n",
    "h = ax.pcolormesh(q, z, empirical_cdf_exceedance, cmap=lisbon, rasterized=True)\n",
    "ax.plot(q, cdf, color='w', linewidth=3)\n",
    "ax.plot(q, cdf, color='k', label='Prior predictive\\nCDF')\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlim(0,QMAX)\n",
    "ax.set_xlabel('Heat flow $q$ ($\\mathrm{mWm}^{-2}$)')\n",
    "ax.set_ylabel('CDF $F$')\n",
    "fig.colorbar(h, cax=cax)\n",
    "cax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "cax.set_yticklabels([\"0\",\"25\",\"50\",\"75\",\"100\"], size='small', rotation=90)\n",
    "cax.set_ylabel(\"Fraction of RGRCD empirical\\nCDF smaller than $F$ (%)\", size='small')\n",
    "ax.legend(fontsize='small');\n",
    "fig.savefig('figures/03-Prior-Predictive.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef8634",
   "metadata": {},
   "source": [
    "Export the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e947440",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results/05-GCP-Parameters.txt', [[np.exp(gcp.lp), gcp.s, gcp.n, gcp.v]],\n",
    "           header = \"p, s, n, v\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96dce58",
   "metadata": {},
   "source": [
    "## References:\n",
    "> Lucazeau, F. (2019). Analysis and mapping of an updated terrestrial heat\n",
    ">    flow data set. Geochemistry, Geophysics, Geosystems, 20, 4001– 4024.\n",
    ">    https://doi.org/10.1029/2019GC008389"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9715fea5",
   "metadata": {},
   "source": [
    "### License\n",
    "```\n",
    "A notebook to determine the parameters of the gamma conjugate prior\n",
    "from regional aggregate heat flow distributions.\n",
    "\n",
    "This file is part of the REHEATFUNQ model.\n",
    "\n",
    "Author: Malte J. Ziebarth (ziebarth@gfz-potsdam.de)\n",
    "\n",
    "Copyright © 2019-2022 Deutsches GeoForschungsZentrum Potsdam,\n",
    "            2022 Malte J. Ziebarth\n",
    "            \n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
