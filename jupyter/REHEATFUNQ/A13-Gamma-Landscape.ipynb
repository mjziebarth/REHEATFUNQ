{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gamma Distribution Landscape\n",
    "This notebook implements the point-of-interest (POI) sampling algorithm\n",
    "and investigates how REHEATFUNQ's minimum distance criterion handles the\n",
    "clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plotconfig import *\n",
    "from cmcrameri.cm import *\n",
    "from pickle import Pickler\n",
    "from pdtoolbox import gamma_cdf, gamma_pdf, gamma_mle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from zeal2022hf import get_cm_colors\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib.patches import Circle\n",
    "from joblib import Memory\n",
    "from reheatfunq.coverings.poisampling import generate_point_of_interest_sampling\n",
    "cache = Memory('.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10.0\n",
    "THETA = 8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(839782973432)\n",
    "n = 200\n",
    "q = THETA*rng.gamma(K, size=(n,n))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "qc = q.copy()\n",
    "rng2 = np.random.default_rng(899283989)\n",
    "def cost(q, i, j):\n",
    "    return (q - qc[i-1,j])**2 + (q - qc[(i+1) % n, j])**2 + (q - qc[i,j-1])**2 + (q - qc[i,(j + 1) % n])**2\n",
    "\n",
    "for k in range(1000000):\n",
    "    i0,j0,i1,j1 = rng2.integers(q.shape[0],size=4)\n",
    "    q0 = qc[i0,j0]\n",
    "    cost_old = cost(q0, i0, j0) + cost(qc[i1,j1], i1, j1)\n",
    "    cost_new = cost(q0, i1, j1) + cost(qc[i1,j1], i0, j0)\n",
    "    if cost_new < cost_old:\n",
    "        qc[i0,j0] = q[i1,j1]\n",
    "        qc[i1,j1] = q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "from libc.stdint cimport uint32_t, uint8_t\n",
    "from cpython.pycapsule cimport PyCapsule_IsValid, PyCapsule_GetPointer\n",
    "from numpy.random cimport bitgen_t\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "cdef double cost(double q, const double[:,::1] qc, size_t i, size_t j, const long[:,::1] stencil) nogil:\n",
    "    cdef size_t n = qc.shape[1]\n",
    "    cdef double cost = 0\n",
    "    cdef long k,ik,jk\n",
    "    for k in range(stencil.shape[0]):\n",
    "        ik = (<long>i) + stencil[k,0]\n",
    "        if ik < 0:\n",
    "            ik += n\n",
    "        ik = ik % n\n",
    "        jk = (<long>j) + stencil[k,1]\n",
    "        if jk < 0:\n",
    "            jk += n\n",
    "        jk = jk % n\n",
    "        cost += (q - qc[ik,jk])**2\n",
    "    return cost\n",
    "\n",
    "# This function from NumPy \"extending.pyx\" example:\n",
    "cdef uint32_t bounded_uint(uint32_t lb, uint32_t ub, bitgen_t *rng) nogil:\n",
    "    cdef uint32_t mask, delta, val\n",
    "    mask = delta = ub - lb\n",
    "    mask |= mask >> 1\n",
    "    mask |= mask >> 2\n",
    "    mask |= mask >> 4\n",
    "    mask |= mask >> 8\n",
    "    mask |= mask >> 16\n",
    "\n",
    "    val = rng.next_uint32(rng.state) & mask\n",
    "    while val > delta:\n",
    "        val = rng.next_uint32(rng.state) & mask\n",
    "\n",
    "    return lb + val\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def dmin_mask(const double[:,::1] xy, double dmin, rng):\n",
    "    assert xy.shape[1] == 2\n",
    "    cdef const long[::1] permutation = rng.permutation(np.arange(xy.shape[0]))\n",
    "    cdef size_t i,j,k,l\n",
    "    cdef uint8_t[::1] mask = np.ones(xy.shape[0], dtype=np.uint8)\n",
    "    cdef double dmin2 = dmin * dmin\n",
    "    with nogil:\n",
    "        for i in range(xy.shape[0]):\n",
    "            k = permutation[i]\n",
    "            if not mask[k]:\n",
    "                continue\n",
    "            for j in range(i+1,xy.shape[0]):\n",
    "                l = permutation[j]\n",
    "                if (xy[k,0]-xy[l,0])**2 + (xy[k,1] - xy[l,1])**2 <= dmin2:\n",
    "                    mask[l] = False\n",
    "    \n",
    "    return mask.base.astype(bool)\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def within_dmin(const double[:,::1] xy_src, const double[:,::] xy_query, double dmin):\n",
    "    assert xy_src.shape[1] == 2\n",
    "    assert xy_query.shape[1] == 2\n",
    "    cdef size_t i,j,k,l\n",
    "    cdef uint8_t[::1] mask = np.ones(xy_query.shape[0], dtype=np.uint8)\n",
    "    cdef double dmin2 = dmin * dmin\n",
    "    with nogil:\n",
    "        for i in range(xy_query.shape[0]):\n",
    "            for j in range(xy_src.shape[0]):\n",
    "                if (xy_src[j,0]-xy_query[i,0])**2 + (xy_src[j,1] - xy_query[i,1])**2 <= dmin2:\n",
    "                    mask[i] = False\n",
    "                    break\n",
    "    \n",
    "    return mask.base.astype(bool)\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def erdnussflips(double[:,::1] qc, size_t steps, rng, size_t s):\n",
    "    cdef size_t n= qc.shape[1]\n",
    "    if qc.shape[0] != n:\n",
    "        raise RuntimeError(\"Must be quadratic.\")\n",
    "    \n",
    "    # Obtain rng:\n",
    "    cdef bitgen_t *bitgen\n",
    "    cdef const char *capsule_name = \"BitGenerator\"\n",
    "    capsule = rng.bit_generator.capsule\n",
    "    if not PyCapsule_IsValid(capsule, capsule_name):\n",
    "        raise ValueError(\"Invalid pointer to anon_func_state\")\n",
    "    bitgen = <bitgen_t *> PyCapsule_GetPointer(capsule, capsule_name)\n",
    "    \n",
    "    # Generate stencil:\n",
    "    cdef long i,j,l\n",
    "    cdef double ds2 = s\n",
    "    ds2 *= s\n",
    "    cdef double dist_i, dist_j\n",
    "    sten = np.empty(((2*s+1)*(2*s+1),2), dtype=np.int64)\n",
    "    mask = np.zeros((2*s+1)*(2*s+1), dtype=bool)\n",
    "    l = 0\n",
    "    for j in range(0,2*s+1):\n",
    "        j -= s\n",
    "        for i in range(0,2*s+1):\n",
    "            i -= s\n",
    "            sten[l,0] = i\n",
    "            sten[l,1] = j\n",
    "            dist_i = i\n",
    "            dist_j = j\n",
    "            if i == 0 and j == 0:\n",
    "                mask[l] = False\n",
    "            elif (i*dist_i) + (j*dist_j) > ds2:\n",
    "                mask[l] = False\n",
    "            else:\n",
    "                mask[l] = True\n",
    "            \n",
    "            l += 1\n",
    "    \n",
    "    cdef size_t k = 0\n",
    "    cdef uint32_t i0,j0,i1,j1\n",
    "    cdef long[:,::1] stencil = sten[mask,:]\n",
    "    cdef double cost_old, cost_new, q0, q1\n",
    "    cdef double cost_prop_0, cost_prop_1\n",
    "    with rng.bit_generator.lock, nogil:\n",
    "        for k in range(steps):\n",
    "            i0 = bounded_uint(0, n-1, bitgen)\n",
    "            j0 = bounded_uint(0, n-1, bitgen)\n",
    "            i1 = bounded_uint(0, n-1, bitgen)\n",
    "            j1 = bounded_uint(0, n-1, bitgen)\n",
    "            q0 = qc[i0,j0]\n",
    "            q1 = qc[i1,j1]\n",
    "            cost_old = cost(q0, qc, i0, j0, stencil) + cost(q1, qc, i1, j1, stencil)\n",
    "            cost_new = cost(q1, qc, i0, j0, stencil) + cost(q0, qc, i1, j1, stencil)\n",
    "            if cost_new < cost_old:\n",
    "                qc[i0,j0] = q1\n",
    "                qc[i1,j1] = q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache.cache\n",
    "def cached_flips(q, steps, seed, s):\n",
    "    qc = q.copy()\n",
    "    rng = np.random.default_rng(seed)\n",
    "    erdnussflips(qc, steps, rng, s)\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = cached_flips(q, 100000000, 899283989, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intermediate/A13-gamma-landscape.pickle','wb') as f:\n",
    "    Pickler(f).dump(qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Geothermal\" Sampling\n",
    "Generate some sampling points that want to explore \"geothermal reservoirs\":\n",
    "\n",
    "*Note: this algorithm is currently unused.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 5000\n",
    "xy = (n-1)*rng.random((M,2))\n",
    "closest_ij = np.round(xy).astype(int)\n",
    "def probability(q):\n",
    "    return np.exp((q-qc.max()) / 40)\n",
    "\n",
    "qxy = qc[*closest_ij.T]\n",
    "p = probability(qxy)\n",
    "mask = rng.random(M) < p\n",
    "xy = xy[mask,:]\n",
    "qxy = qxy[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(q)\n",
    "ax = fig.add_subplot(132)\n",
    "ax.hist(q.flat, bins='auto');\n",
    "twax = ax.twinx()\n",
    "twax.plot(np.linspace(0, qc.max()), probability(np.linspace(0, qc.max())), color='tab:orange')\n",
    "twax.set_ylim(0,1)\n",
    "ax = fig.add_subplot(133)\n",
    "ax.pcolormesh(np.arange(0,n), np.arange(0,n), qc.T)\n",
    "ax.scatter(*xy.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I,J = rng.integers(q.shape[0],size=(2,200))\n",
    "dist = squareform(pdist(np.stack((I,J),axis=1)))\n",
    "mask = np.ones(I.size, dtype=bool)\n",
    "for i,j in np.argwhere(dist <= 5):\n",
    "    if i < j and mask[i]:\n",
    "        mask[j] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = rng.random(qc.shape) < probability(qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I,J = np.argwhere(mask2).T\n",
    "dist = squareform(pdist(np.stack((I,J),axis=1)))\n",
    "mask3 = np.ones(I.size, dtype=bool)\n",
    "for i,j in np.argwhere(dist <= 20):\n",
    "    if i < j and mask3[i]:\n",
    "        mask3[j] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = squareform(pdist(xy))\n",
    "mask5 = np.ones(xy.shape[0], dtype=bool)\n",
    "for i,j in np.argwhere(dist <= 25):\n",
    "    if i < j and mask5[i]:\n",
    "        mask5[j] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.pcolormesh(np.arange(0,n), np.arange(0,n), qc.T)\n",
    "ax.scatter(*xy.T)\n",
    "ax.scatter(*xy[mask5,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(q.flat, density=True)\n",
    "#ax.hist(q[I,J], density=True, histtype='step', bins='auto')\n",
    "#ax.hist(q[I[mask],J[mask]], density=True, histtype='step', bins='auto')\n",
    "ax.hist(qc[mask2], density=True, histtype='step', bins='auto')\n",
    "ax.hist(qc[I[mask3],J[mask3]], density=True, histtype='step', bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "qlsp = np.linspace(q.min(), q.max())\n",
    "ax.plot(qlsp, gamma_cdf(qlsp, K, THETA))\n",
    "ax.plot(np.sort(q.flat), (np.arange(q.size)+1)/q.size)\n",
    "ax.plot(np.sort(qc[mask2]), (np.arange(np.count_nonzero(mask2))+1) / np.count_nonzero(mask2))\n",
    "ax.plot(np.sort(qc[I[mask3],J[mask3]]), (np.arange(np.count_nonzero(mask3))+1) / np.count_nonzero(mask3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-of-Interest Sampling\n",
    "Here we check a type of borehole development where there is a chance to have \"points of interest\", in which\n",
    "there will preferentially be follow-up boreholes in their neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_poi, types_poi = generate_point_of_interest_sampling(100, 0.2, 0.7, 200, 8.0, 89212352)\n",
    "xy_poi, types_poi = generate_point_of_interest_sampling(100, 0.05, 0.8, 200, 8.0, 89212352)\n",
    "\n",
    "closest_ij_poi = np.round(xy_poi).astype(int)\n",
    "q_poi = qc[*closest_ij_poi.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask6 = dmin_mask(xy_poi, 25.0, rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Illustrating Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_cm_colors(vik, 13)\n",
    "color0 = colors[0]\n",
    "color1 = colors[8]\n",
    "color2 = colors[5]\n",
    "color3 = colors[9]\n",
    "color4 = colors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6.0,3.5), dpi=250)\n",
    "#ax_bg = fig.add_axes((0,0,1,1))\n",
    "ax = fig.add_axes((0.08, 0.18, 0.42, 0.89))\n",
    "ax.set_xlabel('x (km)')\n",
    "ax.set_ylabel('y (km)')\n",
    "ax.pcolormesh(np.arange(0,n), np.arange(0,n), qc.T, cmap=bilbao, rasterized=True)\n",
    "markers = ['o','s','^']\n",
    "s = [20,20,15]\n",
    "edgecolor=['#555555','#555555','#bbbbbb']\n",
    "h = []\n",
    "lbls = []\n",
    "for t in [2,0,1]:\n",
    "    maski = types_poi == t\n",
    "    h.append(\n",
    "        ax.scatter(*xy_poi[maski & ~mask6].T, marker=markers[t], s=s[t],\n",
    "                   facecolor='none', edgecolor=edgecolor[t], zorder=2)\n",
    "    )\n",
    "    lbls.append(['Random','POI','Dependent'][t] + '\\n(unselected)')\n",
    "    h.append(\n",
    "        ax.scatter(*xy_poi[mask6 & maski,:].T, marker=markers[t], s=s[t],\n",
    "                    facecolor='k', edgecolor='k', zorder=3)\n",
    "    )\n",
    "    lbls.append(['Random','POI','Dependent'][t] + '\\n(selected)')\n",
    "\n",
    "\n",
    "for i in np.argwhere(mask6).flat:\n",
    "    ax.add_artist(Circle(xy_poi[i,:], radius=25.0, facecolor='none', edgecolor='lightgray', linestyle='--',\n",
    "                  alpha=0.5))\n",
    "ax.set_aspect('equal')\n",
    "ax.text(2, 190, '(a)')\n",
    "\n",
    "ax_leg = fig.add_axes((0.505, 0.69, 0.41, 0.3))\n",
    "ax_leg.set_axis_off()\n",
    "ax_leg.legend(handles=h, labels=lbls, loc='center', ncols=2);\n",
    "\n",
    "\n",
    "#\n",
    "# Now plot the CDFs:\n",
    "#\n",
    "qpl = np.linspace(15, 140, 100)\n",
    "ax2 = fig.add_axes((0.58, 0.345, 0.35, 0.225))\n",
    "qplot1 = np.sort(q_poi)\n",
    "ax2.step(np.concatenate(((0,),qplot1)),\n",
    "        100*np.concatenate(((0,),(np.arange(qplot1.size)+1)/qplot1.size)),\n",
    "         linewidth=1.0, color=color0, where='post',\n",
    "         label='All data')\n",
    "k,t = gamma_mle(qplot1)\n",
    "ax2.plot(qpl, 100*gamma_cdf(qpl, k, t), color=color0, linewidth=0.8, linestyle='--',\n",
    "         label='MLE')\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_xlim(qpl.min(), qpl.max())\n",
    "ax2.set_ylim(0,100)\n",
    "ax2.set_ylabel('CDF (%)', labelpad=0)\n",
    "ax2.text(17, 85, '(b)')\n",
    "ax2.yaxis.set_label_position('right')\n",
    "ax2.legend(fontsize='small', loc='lower right')\n",
    "\n",
    "\n",
    "ax3 = fig.add_axes((ax2.get_position().extents[0], 0.12,\n",
    "                    ax2.get_position().width, 0.225))\n",
    "qplot2 = np.sort(q_poi[mask6])\n",
    "ax3.step(np.concatenate(((0,),qplot2)),\n",
    "         100*np.concatenate(((0,),(np.arange(qplot2.size)+1)/qplot2.size)),\n",
    "         color=color3, linewidth=0.8, where='post',\n",
    "         label='$d_\\\\mathrm{min}$ sample')\n",
    "ax3.text(17, 85, '(c)')\n",
    "k,t = gamma_mle(qplot2)\n",
    "ax3.plot(qpl, 100*gamma_cdf(qpl, k, t), color=color3, linewidth=0.8, linestyle='--',\n",
    "         label='MLE')\n",
    "ax3.set_xlim(qpl.min(), qpl.max())\n",
    "ax3.set_ylim(0,100)\n",
    "ax3.set_ylabel('CDF (%)', labelpad=0)\n",
    "ax3.set_xlabel('Heat flow $q$ ($\\\\mathrm{mW}\\,\\\\mathrm{m}^{-2}$)')\n",
    "ax3.legend(fontsize='small', loc='lower right')\n",
    "\n",
    "\n",
    "fig.savefig('figures/A13-gamma-landscape-preferential-sampling-dmin.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reheatfunq.anomaly.bayes import *\n",
    "from reheatfunq.anomaly.postbackend import *\n",
    "from reheatfunq.anomaly import AnomalyLS1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "qplt = np.linspace(0, 200, 200)\n",
    "ax.plot(qplt, gamma_pdf(qplt, 10.0, 8.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reheatfunq.anomaly import HeatFlowAnomalyPosterior\n",
    "from reheatfunq import GammaConjugatePrior\n",
    "from reheatfunq.regional import default_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp = default_prior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache.cache\n",
    "def reheatfunq_batch_model_comparison_anomaly(Nsamp, Nperm, PH, N=30, Noff=10, k=10.0, theta=8.0, PH_true=100e6,\n",
    "                                              L=100e3, R=5e3, dmin=5e3, d_ano=10e3,\n",
    "                                              point_generator='point-of-interest',\n",
    "                                              data_generator='independent', qc=qc,\n",
    "                                              p_poi=0.05, p_follow_up=0.8, p=np.exp(gcp.lp),\n",
    "                                              s=gcp.s, n=gcp.n, v=gcp.v,\n",
    "                                              quantiles = np.array([0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99]),\n",
    "                                              seed=75564900264581):\n",
    "    \"\"\"\n",
    "    Compare the performance of the heat flow anomaly quantification for different\n",
    "    point set generators.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    if point_generator not in ['point-of-interest','uniform']:\n",
    "        raise ValueError(\"point_generator must be either 'point-of-interest' or 'uniform'.\")\n",
    "    if data_generator not in ['independent','spatial']:\n",
    "        raise ValueError(\"data_generator must be either 'independent' or 'spatial'.\")\n",
    "        \n",
    "    ano = AnomalyLS1980(np.array([(L/2, 0.0), (L/2, L)]), d_ano)\n",
    "\n",
    "    KL = []\n",
    "    tq = []\n",
    "    mean = []\n",
    "    dists = []\n",
    "    for i in range(Nsamp):\n",
    "        print(\"iteration\",i+1,\"of\",Nsamp)\n",
    "        # Generate new data:\n",
    "        if point_generator == 'uniform':\n",
    "            xy_i = (L-1) * rng.random(size=(N,2))\n",
    "        else:\n",
    "            xy_i = generate_point_of_interest_sampling(N, p_poi, p_follow_up, L, R, rng=rng)[0]\n",
    "        \n",
    "        if data_generator == 'independent':\n",
    "            qi_i = theta * rng.gamma(k, size=N)\n",
    "        else:\n",
    "            closest_ij = np.round((np.array(qc.shape)[np.newaxis,:] - 1) * xy_i/L).astype(int)\n",
    "            qi_i = qc[*closest_ij.T]\n",
    "        \n",
    "        # c_i according to unit (mW/m²)\n",
    "        ci_i = ano(xy_i)\n",
    "        ci_i *= 1e3\n",
    "\n",
    "        qi_ano_i = qi_i + PH_true * ci_i\n",
    "        \n",
    "        if np.any(np.isnan(qi_ano_i)):\n",
    "            print(\"------------------------------------------\")\n",
    "            print(\"xy_i:\")\n",
    "            print(xy_i)\n",
    "            print(\"ci_i:\")\n",
    "            print(ci_i)\n",
    "            print(\"qi_ano_i:\")\n",
    "            print(qi_ano_i)\n",
    "            print(\"------------------------------------------\")\n",
    "            raise RuntimeError(\"Found qi_ano_i is nan!\")\n",
    "        \n",
    "        # Full data set posterior:\n",
    "        gcp = GammaConjugatePrior(p, s, n, v)\n",
    "        try:\n",
    "            post_i = HeatFlowAnomalyPosterior(qi_ano_i, *xy_i.T, ano, gcp, 0.0, rng=seed)\n",
    "        except:\n",
    "            with open('error-config.pickle','wb') as f:\n",
    "                Pickler(f).dump(((qi_ano_i, *xy_i.T, ano, gcp, 0.0), dict(rng=seed)))\n",
    "            raise RuntimeError(\"Error in init.\")\n",
    "            \n",
    "        \n",
    "        pdf_cmp_3 = post_i.pdf(PH)\n",
    "        if quantiles is not None:\n",
    "            try:\n",
    "                tail_i = post_i.tail_quantiles(quantiles)\n",
    "            except RuntimeError as e:\n",
    "                with open('error-config.pickle','wb') as f:\n",
    "                    Pickler(f).dump(((qi_ano_i, *xy_i.T, ano, gcp, 0.0), dict(rng=seed)))\n",
    "                raise e\n",
    "        mask = pdf_cmp_3 > 0\n",
    "\n",
    "        try:\n",
    "            post_batch_i = HeatFlowAnomalyPosterior(qi_ano_i, *xy_i.T, ano, gcp, dmin, n_bootstrap=Nperm, rng=seed)\n",
    "        except RuntimeError as e:\n",
    "            args = (qi_ano_i, *xy_i.T, None, gcp, dmin)\n",
    "            kwargs = dict(n_bootstrap=Nperm, rng=seed)\n",
    "            with open('error-config2.pickle','wb') as f:\n",
    "                Pickler(f).dump({\n",
    "                    \"args\" : args,\n",
    "                    \"kwargs\" : kwargs,\n",
    "                    \"ano_args\" : (np.array([(L/2, 0.0), (L/2, L)]), d_ano)\n",
    "                })\n",
    "            raise e\n",
    "        qi_batch_i = [post_batch_i.q[ids] for w,j,ids in post_batch_i.bootstrap]\n",
    "        ci_batch_i = [post_batch_i.c[j,ids] for w,j,ids in post_batch_i.bootstrap]\n",
    "\n",
    "        pdf_batch_i = post_batch_i.pdf(PH)\n",
    "        if quantiles is not None:\n",
    "            try:\n",
    "                tail_batch_i = post_batch_i.tail_quantiles(quantiles)\n",
    "            except RuntimeError as e:\n",
    "                with open('error-config.pickle','wb') as f:\n",
    "                    Pickler(f).dump((qi_batch_i, ci_batch_i, np.ones(Nperm), p, s, n, v, 1.0, 1e-5))\n",
    "                raise e\n",
    "\n",
    "        pdf_batch_old_i = np.zeros_like(PH) + np.NaN\n",
    "        tail_batch_old_i = np.zeros_like(quantiles)+ np.NaN\n",
    "\n",
    "        # Kullback-Leibler distance (kind of)\n",
    "        KL.append((np.sum(pdf_cmp_3[mask] * np.log(pdf_cmp_3[mask] / pdf_batch_i[mask])),\n",
    "                   np.sum(pdf_cmp_3[mask] * np.log(pdf_cmp_3[mask] / pdf_batch_old_i[mask]))))\n",
    "    \n",
    "        # The distribution's mean:\n",
    "        dPH = PH[1] - PH[0]\n",
    "        mean.append(((PH * pdf_cmp_3 * dPH).sum(), (PH * pdf_batch_i * dPH).sum(),\n",
    "                     (PH * pdf_batch_old_i * dPH).sum()))\n",
    "\n",
    "        dists.append(np.stack((pdf_cmp_3, pdf_batch_i, pdf_batch_old_i)))\n",
    "        \n",
    "        if quantiles is not None:\n",
    "            tq.append((tail_i, tail_batch_i, tail_batch_old_i))\n",
    "\n",
    "    KL = np.array(KL)\n",
    "    mean = np.array(mean)\n",
    "    \n",
    "    return KL, mean, dists, tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PH = np.linspace(0.0, 8e8, 100)\n",
    "PH_true=100e6\n",
    "quantiles = np.array([0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_illustration(PH, N=50, k=10.0, theta=8.0, PH_true=100e6,\n",
    "                      L=100e3, R=5e3, dmin=5e3, d_ano=10e3,\n",
    "                       point_generator='point-of-interest',\n",
    "                       data_generator='independent', qc=qc,\n",
    "                       p_poi=0.12, p_follow_up=0.8, p=1.0, s=0.0, n=0.0, v=0.0,\n",
    "                       quantiles = np.array([0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99]),\n",
    "                       seed=75564900264581):\n",
    "        \n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    if point_generator not in ['point-of-interest','uniform']:\n",
    "        raise ValueError(\"point_generator must be either 'point-of-interest' or 'uniform'.\")\n",
    "    if data_generator not in ['independent','spatial']:\n",
    "        raise ValueError(\"data_generator must be either 'independent' or 'spatial'.\")\n",
    "        \n",
    "    ano = AnomalyLS1980(np.array([(L/2, 0.0), (L/2, L)]), d_ano)\n",
    "\n",
    "    if point_generator == 'uniform':\n",
    "        xy_i = (L-1) * rng.random(size=(N,2))\n",
    "    else:\n",
    "        xy_i = generate_point_of_interest_sampling(N, p_poi, p_follow_up, L, R, rng=rng)[0]\n",
    "    \n",
    "    if data_generator == 'independent':\n",
    "        qi_i = theta * rng.gamma(10.0, size=N)\n",
    "    else:\n",
    "        closest_ij = np.round((np.array(qc.shape)[np.newaxis,:] - 1) * xy_i/L).astype(int)\n",
    "        qi_i = qc[*closest_ij.T]\n",
    "\n",
    "    # c_i according to unit (mW/m²)\n",
    "    ci_i = ano(xy_i)\n",
    "    ci_i *= 1e3\n",
    "\n",
    "    xy_plot = np.stack(\n",
    "        (np.linspace(0, L, 101),\n",
    "         np.zeros(101)),\n",
    "        axis=1\n",
    "    )\n",
    "    ci_plot = ano(xy_plot) * 1e3\n",
    "\n",
    "    qi_ano_i = qi_i + PH_true * ci_i\n",
    "\n",
    "    fig = plt.figure(figsize=(12,4.5))\n",
    "    ax = fig.add_subplot(131)\n",
    "    ax.plot(xy_plot[:,0], ci_plot * PH_true)\n",
    "    ax.scatter(xy_i[:,0], qi_i, marker='.')\n",
    "    ax.scatter(xy_i[:,0], qi_ano_i, marker='^')\n",
    "\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax2.pcolormesh(np.linspace(0, L, qc.shape[0]),\n",
    "                   np.linspace(0, L, qc.shape[1]),\n",
    "                   qc.T)\n",
    "    ax2.scatter(*xy_i.T, c=qi_i, vmin=qc.min(),\n",
    "                vmax=qc.max(), edgecolor='k')\n",
    "    ax2.plot(*np.array([(L/2, 0.0), (L/2, L)]).T,\n",
    "             color='k', linewidth=1.0)\n",
    "    ax2.set_xlim(0, L)\n",
    "    ax2.set_ylim(0, L)\n",
    "\n",
    "    gcp = GammaConjugatePrior(p, s, n, v)\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    post2 = HeatFlowAnomalyPosterior(qi_ano_i, *xy_i.T, ano, gcp, dmin, n_bootstrap=200, rng=seed)\n",
    "    post = HeatFlowAnomalyPosterior(qi_ano_i, *xy_i.T, ano, gcp, 0.0, rng=seed)\n",
    "    ax3.plot(PH, post.pdf(PH))\n",
    "    ax3.axvline(PH_true, color='k', linewidth=1.0)\n",
    "    ax3.plot(PH, post2.pdf(PH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_illustration(PH, PH_true=PH_true, quantiles=quantiles,\n",
    "                  data_generator='spatial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats, io\n",
    "from pstats import SortKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsamp = 10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "try:\n",
    "    reheatfunq_batch_model_comparison_anomaly(Nsamp, 1000, PH, PH_true=PH_true, quantiles=quantiles,\n",
    "                                              data_generator='spatial')\n",
    "finally:\n",
    "    pr.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc.shape, qc.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = io.StringIO()\n",
    "sortby = SortKey.TIME\n",
    "ps = pstats.Stats(pr).sort_stats(sortby)\n",
    "ps.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL, mean, dists, tq = reheatfunq_batch_model_comparison_anomaly(Nsamp, 1000, PH, PH_true=PH_true, quantiles=quantiles,\n",
    "                                              data_generator='spatial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(PH, dists[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,3))\n",
    "ax = fig.add_subplot(121)\n",
    "iq = 3\n",
    "y0 = np.array([t[0][iq] for t in tq])\n",
    "y1 = np.array([t[1][iq] for t in tq])\n",
    "ax.hist(100*(y0-PH_true)/PH_true, label='all', bins='auto', density=True)\n",
    "ax.hist(100*(y1-PH_true)/PH_true, label='in likelihood', histtype='step', bins='auto', density=True)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "#ax.set_yscale('log')\n",
    "ax.hist(100*(y0-PH_true)/PH_true, label='all', bins='auto', density=True)\n",
    "ax.hist(100*(y1-PH_true)/PH_true, label='in likelihood', histtype='step', bins='auto', density=True)\n",
    "ax.legend()\n",
    "ax.set_title(quantiles[iq]);\n",
    "ax.set_xlim(-100, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,3))\n",
    "#ax_bg = fig.add_axes((0,0,1,1))\n",
    "ax = fig.add_axes((0.065, 0.15, 0.27, 0.78))\n",
    "ax.hist(100*(y0-PH_true)/PH_true, label='all', bins='auto', density=True, color=color1,\n",
    "        histtype='stepfilled')\n",
    "ax.hist(100*(y1-PH_true)/PH_true, label='in likelihood', histtype='step', bins='auto', density=True, color=color0)\n",
    "ax.axvline(0.0, linewidth=0.8, color='k', linestyle='--')\n",
    "ax.set_ylabel('Density ($10^{-3}$)')\n",
    "ax.set_xlabel('Deviation from true value (%)', x=0.85, ha='center')\n",
    "ax.set_title(\"Median $P_H$\", x=0.9, ha='center');\n",
    "ax.set_xlim(-100, 150)\n",
    "ax.set_yticks(ax.get_yticks())\n",
    "ax.set_yticklabels([str(round(1e3*yt)) for yt in ax.get_yticks()])\n",
    "ax.set_xticks([-100, 0, 100, 150])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax2 = fig.add_axes((ax.get_position().extents[2], 0.15, 0.22, 0.78))\n",
    "ax2.set_yticks([])\n",
    "ax2.set_ylim(ax.get_ylim())\n",
    "ax2.hist(100*(y0-PH_true)/PH_true, label='All data', bins='auto', density=True, color=color1)\n",
    "ax2.hist(100*(y1-PH_true)/PH_true, label='$d_\\\\mathrm{min}$ samples', histtype='step', bins='auto', density=True, color=color0)\n",
    "ax2.set_xlim(ax.get_xlim()[1], ax2.get_xlim()[1])\n",
    "ax2.set_xscale('log')\n",
    "ax2.legend()\n",
    "ax2.spines['left'].set_visible(False)\n",
    "ax2.plot((150,150), ax2.get_ylim()[1]*np.array((0.995, 0.95)),\n",
    "        clip_on=False, color='k', linewidth=ax2.spines[\"top\"].get_linewidth())\n",
    "\n",
    "\n",
    "ax = fig.add_axes((0.65, 0.15, 0.34, 0.78))\n",
    "ax.set_title(\"Mean $P_H$\")\n",
    "ax.hist(100*(mean[:,0]-PH_true)/PH_true, bins='auto', density=True, color=color1,\n",
    "        histtype='stepfilled')\n",
    "ax.hist(100*(mean[:,1]-PH_true)/PH_true, bins='auto', histtype='step', density=True, color=color0)\n",
    "#ax.hist(mean[:,2], bins='auto', histtype='step', density=True);\n",
    "ax.axvline(0.0, color='k', linewidth=0.8, linestyle='--')\n",
    "ax.set_ylabel('Density ($10^{-3}$)')\n",
    "ax.set_xlabel('Deviation from true value (%)')\n",
    "ax.set_yticks(ax.get_yticks())\n",
    "ax.set_yticklabels([str(round(1e3*yt)) for yt in ax.get_yticks()]);\n",
    "\n",
    "fig.savefig('figures/A13-POI-Sampling-Median-Mean-P_H.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdtoolbox.gof.statistics import _anderson_darling\n",
    "from pdtoolbox.distributions import gamma_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferential_sampling_dmin_monte_carlo(N_MC, Nsamp, p_poi, p_follow_up, rng, L, R, dmin):\n",
    "    A2 = np.empty((N_MC, 2))\n",
    "    A2_dmin = np.empty((N_MC,2))\n",
    "    counter = []\n",
    "    for i in range(N_MC):\n",
    "        # Generate a sampling:\n",
    "        xy_poi, types_poi = generate_point_of_interest_sampling(Nsamp, p_poi, p_follow_up, L, R, rng=rng)\n",
    "        closest_ij_poi = np.round(xy_poi).astype(int)\n",
    "        q_poi = qc[*closest_ij_poi.T]\n",
    "        \n",
    "        # Generate the filtered data:\n",
    "        mask = dmin_mask(xy_poi, dmin, rng)\n",
    "        q_poi_dmin = q_poi[mask]\n",
    "        m_poi = q_poi_dmin.size\n",
    "        \n",
    "        counter.append(m_poi)\n",
    "        \n",
    "        # Evaluate the cdfs:\n",
    "        cdf_poi = np.sort(gamma_cdf(q_poi, K, THETA))\n",
    "        cdf_poi_dmin = np.sort(gamma_cdf(q_poi_dmin, K, THETA))\n",
    "        \n",
    "        # Anderson-Darling statistic:\n",
    "        A2[i,0] = _anderson_darling(cdf_poi.reshape((1,-1)), 0.0, True)[0]\n",
    "        A2_dmin[i,0] = _anderson_darling(cdf_poi_dmin.reshape((1,-1)), 0.0, True)[0]\n",
    "\n",
    "    for i in range(N_MC):\n",
    "        q_uni = THETA * rng.gamma(K, size=Nsamp)\n",
    "        cdf = gamma_cdf(q_uni, K, THETA)\n",
    "        \n",
    "        # Evaluate the CDFs:\n",
    "        cdf_uni = np.sort(cdf)\n",
    "        cdf_uni_dmin = np.sort(cdf[:counter[i]])\n",
    "\n",
    "        # Anderson-Darling statistic:\n",
    "        A2[i,1] = _anderson_darling(cdf_uni.reshape((1,-1)), 0.0, True)[0]\n",
    "        A2_dmin[i,1] = _anderson_darling(cdf_uni_dmin.reshape((1,-1)), 0.0, True)[0]\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        \n",
    "    return A2, A2_dmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMIN = [2.0, 8.0, 20.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = []\n",
    "A2_dmin = []\n",
    "for dmin in [2.0, 8.0, 20.0]:\n",
    "    A2_i, A2_dmin_i = preferential_sampling_dmin_monte_carlo(10000, 200,  0.2, 0.7, rng, 200.0, 8.0, dmin)\n",
    "    A2.append(A2_i)\n",
    "    A2_dmin.append(A2_dmin_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "#ax_bg = fig.add_axes((0,0,1,1))\n",
    "axi_w = 0.24\n",
    "x0l = 0.08\n",
    "ax0_w = 0.33 * 2 + axi_w\n",
    "ax0 = fig.add_axes((x0l, 0.6, ax0_w, 0.33))\n",
    "ax0.hist(A2[0][:,1], bins='auto', label='i.i.d.', density=True, color=color1, histtype='stepfilled')\n",
    "ax0.hist(A2[0][:,0], bins='auto', histtype='step', label='Preferential sampling', density=True, color=color0)\n",
    "ax0.legend()\n",
    "ax0.set_xlabel('Anderson-Darling statistic A²')\n",
    "ax0.set_ylabel('Density')\n",
    "ax0.set_title('No $d_\\mathrm{min}$',loc='left')\n",
    "ax0.set_xlim(0,10 * ax0_w/axi_w)\n",
    "ax0.annotate('continues', (10 * ax0_w/axi_w, 0.1), (0.85 * 10 * ax0_w/axi_w, 0.1),\n",
    "             arrowprops={\n",
    "                 'arrowstyle' : '->'\n",
    "             }, ha='left', va='center')\n",
    "ax0.set_ylim(0, 1.8)\n",
    "ax0.text(0.3, 1.6, '(a)')\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    ax = fig.add_axes((0.08 + 0.33 * i, 0.1, axi_w, 0.33))\n",
    "    ax.hist(A2_dmin[i][:,1], bins='auto', color=color1, density=True)\n",
    "    ax.hist(A2_dmin[i][:,0], bins='auto', histtype='step', density=True, color=color0);\n",
    "    ax.set_xlabel('A²')\n",
    "    ax.set_title(f'$d_\\mathrm{{min}}={DMIN[i]}\\,\\mathrm{{km}}$')\n",
    "    ax.set_xlim(0,10)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_ylim(0, 1.8)\n",
    "    ax.text(0.3 if i != 2 else 0.6, 1.6, ['(b)','(c)','(d)'][i])\n",
    "\n",
    "fig.savefig('figures/A13-A2-improvement-with-dmin.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(np.sort(q.flat), (np.arange(q.size)+1)/q.size)\n",
    "ax.plot(np.sort(q_poi), (np.arange(q_poi.size)+1) / q_poi.size)\n",
    "ax.plot(np.sort(q_poi[mask6]), (np.arange(np.count_nonzero(mask6))+1) / np.count_nonzero(mask6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "```\n",
    "Investigating a model of preferentially clustered sampling on a\n",
    "gamma heat flow landscape, and the mitigating effect of the dmin\n",
    "criterion thereon.\n",
    "\n",
    "This file is part of the REHEATFUNQ model.\n",
    "\n",
    "Author: Malte J. Ziebarth (ziebarth@gfz-potsdam.de)\n",
    "\n",
    "Copyright © 2019-2022 Deutsches GeoForschungsZentrum Potsdam,\n",
    "            2023 Malte J. Ziebarth\n",
    "            \n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}