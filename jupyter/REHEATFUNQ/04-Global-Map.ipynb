{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map of the New Global Heat Flow Database\n",
    "This notebook plots a global* map of the filtered heat flow data. Specific regions of interest,\n",
    "where the *random global $R$-disk covering* of notebook `03-Gamma-Conjugate-Prior-Parameters`\n",
    "contains disks, are plotted as tiles on the global map in more detail and less distorted.\n",
    "Coordinates between the tiles are warped by solving the diffusion equation on projected coordinates.\n",
    "\n",
    "\n",
    "<font size=\"1\">*) Some parts to the North/South/East/West are missing where there are no heat flow data.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats(\"retina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from plotconfig import *\n",
    "import scipy.sparse as sp\n",
    "from pickle import Unpickler\n",
    "from pyproj import Proj, Geod\n",
    "from cache import cached_call\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from flottekarte import Map, GeoJSON\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.patches import Polygon as MPolygon, Circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results From Other Notebooks\n",
    "### 03-Gamma-Conjugate-Prior-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/03-gamma-conjugate-prior-results.json','r') as f:\n",
    "    conjugate_prior_results = json.load(f)\n",
    "    \n",
    "cgp_lola = np.stack(([c[0][0] for c in conjugate_prior_results],\n",
    "                     [c[0][1] for c in conjugate_prior_results]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-Load-and-filter-NGHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAT, LON, LAT = np.load('intermediate/heat-flow-selection-mW_m2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02-Study-Area-Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intermediate/02-Geometry.pickle','rb') as f:\n",
    "    geometry = Unpickler(f).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiled Map\n",
    "Here, we create a global map from a tiling of local maps. Inbetween the local maps,\n",
    "the global map is warped by solving the diffusing equation for coordinates given\n",
    "the boundary conditions at the local map boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_strings = [\n",
    "    \"+proj=lcc +lon_0=-113 +lat_0=41 +lat_1=33 +lat_2=50\",\n",
    "    \"+proj=lcc +lon_0=-76.5 +lat_0=0.0 +lat_1=-10.0 +lat_2=11\",\n",
    "    \"+proj=lcc +lon_0=5 +lat_0=50 +lat_1=40 +lat_2=60\",\n",
    "    \"+proj=lcc +lon_0=40 +lat_0=0 +lat_1=-10 +lat_2=11\",\n",
    "    \"+proj=lcc +lon_0=88 +lat_0=42 +lat_1=36 +lat_2=48\",\n",
    "    \"+proj=lcc +lon_0=119 +lat_0=41 +lat_1=37 +lat_2=45\",\n",
    "    \"+proj=lcc +lon_0=77 +lat_0=14 +lat_1=10 +lat_2=20\",\n",
    "    \"+proj=lcc +lon_0=143 +lat_0=-38 +lat_1=-43 +lat_2=-35\",\n",
    "    \"+proj=lcc +lon_0=-48 +lat_0=-26 +lat_1=-24 +lat_2=-28\",\n",
    "    \"+proj=lcc +lon_0=42 +lat_0=39 +lat_1=33 +lat_2=-47\",\n",
    "    \"+proj=lcc +lon_0=75 +lat_0=62 +lat_1=57 +lat_2=63\",\n",
    "]\n",
    "\n",
    "xlims = [\n",
    "    (-1.1e6, 1.2e6),\n",
    "    (-6e5, 1e5),\n",
    "    (-1.4e6, 1.4e6),\n",
    "    (-6e5, 5e5),\n",
    "    (-5e5, 5e5),\n",
    "    (-1e6, 8e5),\n",
    "    (-7e5, 8e5),\n",
    "    (-5e5, 5e5),\n",
    "    (-5e5, 5e5),\n",
    "    (-8e5, 8e5),\n",
    "    (-3e5, 3e5),\n",
    "]\n",
    "ylims = [\n",
    "    (-1e6, 1e6),\n",
    "    (-3e5, 3e5),\n",
    "    (-2e6, 2e6),\n",
    "    (-4e5, 3e5),\n",
    "    (-7e5, 5e5),\n",
    "    (-1e6, 1e6),\n",
    "    (-7e5, 8e5),\n",
    "    (-5e5, 5e5),\n",
    "    (-5e5, 5e5),\n",
    "    (-1.1e6, 1e6),\n",
    "    (-3e5, 3e5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlims = np.array(xlims)\n",
    "ylims = np.array(ylims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coast lines from the [GSHHG](https://www.soest.hawaii.edu/pwessel/gshhg/) (Wessel & Smith, 1996). The GeoJSONs required for the following code to work can be generated from the ESRI shapefile versions of the GSHHG,\n",
    "for instance using QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gshhs_l_1 = [GeoJSON('data/GSHHS_l_1.geojson', ps, xlim=xl, ylim=yl)\n",
    "             for ps,xl,yl in zip(proj_strings,xlims,ylims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gshhs_c_1 = GeoJSON('data/GSHHS_c_1_selected.geojson', f'+proj=eqc +R={180.0/np.pi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribute the relevant data across the local regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "heat = []\n",
    "gcp_xy = []\n",
    "gcp_plotted = np.zeros(cgp_lola.shape[0], dtype=bool)\n",
    "for ps,xl,yl in zip(proj_strings, xlims, ylims):\n",
    "    x,y = Proj(ps)(LON, LAT)\n",
    "    mask = (x >= xl[0]) & (x <= xl[1]) & (y >= yl[0]) & (y <= yl[1])\n",
    "    X.append(x[mask])\n",
    "    Y.append(y[mask])\n",
    "    heat.append(HEAT[mask])\n",
    "    \n",
    "    # Gamma conjugate prior results:\n",
    "    x,y = Proj(ps)(cgp_lola[:,0], cgp_lola[:,1])\n",
    "    mask = (x >= xl[0]) & (x <= xl[1]) & (y >= yl[0]) & (y <= yl[1])\n",
    "    gcp_plotted |= mask\n",
    "    gcp_xy.append((x[mask], y[mask]))\n",
    "\n",
    "if not np.all(gcp_plotted):\n",
    "    raise RuntimeError(\"Not all GCP results plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the coordinate diffusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diffusion_matrix_vector(x_fig, y_fig, Dx, Dy, xdata, ydata, londata, latdata):\n",
    "    \"\"\"\n",
    "    Solve diffusion equation on the coordinate grid.\n",
    "    \"\"\"\n",
    "    # Layout of grid:\n",
    "    # (nx,ny)\n",
    "    nx = x_fig.size\n",
    "    ny = y_fig.size\n",
    "    n = nx*ny\n",
    "    A = sp.lil_matrix((n,n))\n",
    "    v_lon = np.zeros(n)\n",
    "    v_lat = np.zeros(n)\n",
    "    dx = Dx / (nx-1)\n",
    "    dy = Dy / (ny-1)\n",
    "    \n",
    "    # In which bin do the data fall?\n",
    "    data_indices = dict()\n",
    "    for k,(x,y) in enumerate(zip(xdata,ydata)):\n",
    "        i = min(max(round(nx*x),0),nx-1)\n",
    "        j = min(max(round(ny*y),0),ny-1)\n",
    "        if (i,j) not in data_indices:\n",
    "            data_indices[(i,j)] = [k]\n",
    "        else:\n",
    "            data_indices[(i,j)].append(k)\n",
    "    \n",
    "    idx2 = 1.0 / dx**2\n",
    "    idy2 = 1.0 / dy**2\n",
    "    for k in range(n):\n",
    "        i = k // ny\n",
    "        j = k % ny\n",
    "        # Proceed depending on whether we are in a constrained\n",
    "        # point or not:\n",
    "        if (i,j) in data_indices:\n",
    "            # External boundary:\n",
    "            if (i,j) in data_indices:\n",
    "                A[k,k] = 1.0\n",
    "                loda_ij = [londata[l] for l in data_indices[(i,j)]]\n",
    "                lada_ij = [latdata[l] for l in data_indices[(i,j)]]\n",
    "                v_lon[k] = sum(loda_ij) / len(loda_ij)\n",
    "                v_lat[k] = sum(lada_ij) / len(lada_ij)\n",
    "\n",
    "        elif i == 0 or i == nx-1 or j == 0 or j == ny-1:\n",
    "            # We are on the boundary. Fixed value boundary condition!\n",
    "            A[k,k] = 1.0\n",
    "\n",
    "            # Now set the boundary conditions.\n",
    "            v_lon[k] = -180.0 + 360.0 / (nx-1) * i\n",
    "            v_lat[k] =  -90.0 + 180.0 / (ny-1) * j\n",
    "            if i == 0:\n",
    "                v_lon[k] = -180.0\n",
    "            elif i == nx-1:\n",
    "                v_lon[k] = 180.0\n",
    "            if j == 0:\n",
    "                v_lat[k] = -90.0\n",
    "            elif j == ny-1:\n",
    "                v_lat[k] = 90.0\n",
    "\n",
    "        else:\n",
    "            # Not on x or y boundary.\n",
    "            A[k,k] = -2 * (idx2 + idy2);\n",
    "            A[k,k-ny] = idx2\n",
    "            A[k,k+ny] = idx2\n",
    "            A[k,k-1]  = idy2\n",
    "            A[k,k+1]  = idy2\n",
    "        \n",
    "    return A.tocsc(), v_lon, v_lat    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility code for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_xy(x, y, ax_xlim, ax_ylim, ax_pos_x0_x1_y0_y1):\n",
    "    \"\"\"\n",
    "    Reprojects coordinates from the axis coordinates to\n",
    "    the global figure coordinates.\n",
    "    \"\"\"\n",
    "    x0,x1,y0,y1 = ax_pos_x0_x1_y0_y1\n",
    "    ax_pos = (x0, y0, x1-x0, y1-y0)\n",
    "    rel_ax_x = (x-ax_xlim[0]) / (ax_xlim[1] - ax_xlim[0])\n",
    "    rel_ax_y = (y-ax_ylim[0]) / (ax_ylim[1] - ax_ylim[0])\n",
    "    rel_fig_x = ax_pos[0] + rel_ax_x * ax_pos[2]\n",
    "    rel_fig_y = ax_pos[1] + rel_ax_y * ax_pos[3]\n",
    "    return rel_fig_x, rel_fig_y\n",
    "\n",
    "def construct_coordinate_constraints(ax_pos_x0_x1_y0_y1, xlim_real, ylim_real, xlims, ylims, proj_strings):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    m = 50\n",
    "    rel_x = []\n",
    "    rel_y = []\n",
    "    lon = []\n",
    "    lat = []\n",
    "    for i in range(len(axes)):\n",
    "        x_i = np.concatenate((np.linspace(*xlims[i,:],m+1)[:-1], np.ones(m)*xlims[i,1],\n",
    "                              np.linspace(*xlims[i,:],m+1)[:-1][::-1], np.ones(m)*xlims[i,0]))\n",
    "        y_i = np.concatenate((np.ones(m)*ylims[i,0], np.linspace(*ylims[i,:],m+1)[:-1],\n",
    "                              np.ones(m)*ylims[i,1], np.linspace(*ylims[i,:],m+1)[:-1][::-1]))\n",
    "        rel_x_i, rel_y_i = reproject_xy(x_i, y_i, xlim_real[i,:], ylim_real[i,:], ax_pos_x0_x1_y0_y1[i,:])\n",
    "        rel_x.append(rel_x_i)\n",
    "        rel_y.append(rel_y_i)\n",
    "        lon_i, lat_i = Proj(proj_strings[i])(x_i, y_i, inverse=True)\n",
    "        lon.append(lon_i)\n",
    "        lat.append(lat_i)\n",
    "\n",
    "    return np.concatenate(rel_x), np.concatenate(rel_y), np.concatenate(lon), np.concatenate(lat)\n",
    "\n",
    "\n",
    "def solve_diffusion_system(xg_rel, yg_rel, figwidth, figheight, rel_x, rel_y, fig_lon, fig_lat):\n",
    "    \"\"\"\n",
    "    Assemble the diffusion system and solve it.\n",
    "    \"\"\"\n",
    "    nx = xg_rel.size\n",
    "    ny = yg_rel.size\n",
    "    A, v_lon, v_lat = cached_call(generate_diffusion_matrix_vector, xg_rel, yg_rel,\n",
    "                                  figwidth, figheight, rel_x, rel_y, fig_lon, fig_lat)\n",
    "    lon_grid_diff = spsolve(A,v_lon).reshape((nx, ny))\n",
    "    lat_grid_diff = spsolve(A,v_lat).reshape((nx, ny))\n",
    "    return lon_grid_diff, lat_grid_diff\n",
    "\n",
    "\n",
    "def project_polygon(multipolygons_lola, axes_x0_x1_y0_y1, xlims, ylims, xlim_real, ylim_real, proj_strings,\n",
    "                    figwidth, figheight, lon_min, lon_max, lat_min, lat_max, nx=200, ny=100):\n",
    "    \"\"\"\n",
    "    This function projects the coordinates of a set of polygons to the warped\n",
    "    coordinate space of the background global axis. It performs the following steps:\n",
    "       1) construct the coordinate constraints from the local maps\n",
    "          in relative coordinates of the global map.\n",
    "       2) Create an affine mapping of the global lon/lat range to\n",
    "          the cropped section displayed in the global map. This will\n",
    "          be the coordinate constraint on the global map boundary.\n",
    "       3) Solve the diffusion system on a grid in the global map\n",
    "       4) Index the solution points of the diffusion system in a 2D KDTree\n",
    "          in global map coordinates. This tree maps lon/lat coordinates\n",
    "          to relative x/y of the global map.\n",
    "       5) Project each point of the multipolygons by computing the 5 nearest\n",
    "          neighbors of the lon/lat coordinate and performing Nadaraya-Watson\n",
    "          interpolation of the relative x/y coordinates using the geodesic\n",
    "          distance and a Gaussian kernel.\n",
    "    \"\"\"\n",
    "    rel_x, rel_y, fig_lon, fig_lat \\\n",
    "        = construct_coordinate_constraints(axes_x0_x1_y0_y1, xlim_real, ylim_real, xlims, ylims, proj_strings)\n",
    "    \n",
    "    # Scale according to latitude boundaries:\n",
    "    bx = (lon_min + 180) / 360.0\n",
    "    ax = (lon_max - lon_min) / 360.0\n",
    "    rel_x =  ax * rel_x + bx\n",
    "\n",
    "    by = (lat_min + 90) / 180.0\n",
    "    ay = (lat_max - lat_min) / 180.0\n",
    "    rel_y =  ay * rel_y + by\n",
    "\n",
    "    xg_rel = np.linspace(0, 1, nx)\n",
    "    yg_rel = np.linspace(0, 1, ny)\n",
    "\n",
    "\n",
    "    xg_relg, yg_relg = np.meshgrid(xg_rel,yg_rel,indexing='ij')\n",
    "    #A, v_lon, v_lat = cached_call(generate_diffusion_matrix_vector, xg_rel, yg_rel,\n",
    "    #                              figwidth, figheight, rel_x, rel_y, fig_lon, fig_lat)\n",
    "    #lon_grid_diff = spsolve(A,v_lon).reshape((nx, ny))\n",
    "    #lat_grid_diff = spsolve(A,v_lat).reshape((nx, ny))\n",
    "    lon_grid_diff, lat_grid_diff = cached_call(solve_diffusion_system, xg_rel, yg_rel,\n",
    "                                               figwidth, figheight, rel_x, rel_y, fig_lon, fig_lat)\n",
    "\n",
    "\n",
    "    # Populate the tree that maps projected coordinates to inverse:\n",
    "    tree = KDTree(np.stack((lon_grid_diff.flat, lat_grid_diff.flat), axis=1))\n",
    "    tree_x = xg_relg.flat\n",
    "    tree_y = yg_relg.flat\n",
    "\n",
    "    # Now compute the polygon coordinates:\n",
    "    gshhs_c_xy = []\n",
    "    geod = Geod(ellps=\"WGS84\")\n",
    "    nn = 5\n",
    "    for mpoly in multipolygons_lola:\n",
    "        for poly in mpoly:\n",
    "            neighbors = tree.query(poly[0], nn)\n",
    "            distance = np.empty((poly[0].shape[0],nn))\n",
    "            for i in range(nn):\n",
    "                distance[:,i] = geod.inv(poly[0][:,0], poly[0][:,1], lon_grid_diff.flat[neighbors[1][:,i]],\n",
    "                                         lat_grid_diff.flat[neighbors[1][:,i]])[2]\n",
    "            # Set the coordinates:\n",
    "            weights = np.exp(-0.5 * distance**2 / 1e6**2)\n",
    "            weights /= weights.sum(axis=1)[:,np.newaxis]\n",
    "            poly_xy = np.zeros(poly[0].shape)\n",
    "            poly_xy[:,0] = (weights * tree_x[neighbors[1]]).sum(axis=1)\n",
    "            poly_xy[:,1] = (weights * tree_y[neighbors[1]]).sum(axis=1)\n",
    "            \n",
    "            # Crop back:\n",
    "            poly_xy[:,0] -= bx\n",
    "            poly_xy[:,0] /= ax\n",
    "            poly_xy[:,1] -= by\n",
    "            poly_xy[:,1] /= ay\n",
    "            gshhs_c_xy.append(poly_xy)\n",
    "    \n",
    "    \n",
    "    return gshhs_c_xy, lon_grid_diff, lat_grid_diff, (xg_rel-bx)/ax, (yg_rel - by) / ay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matplotlib Artist for handling circles in a legend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleHandler:\n",
    "    def __init__(self, scale=1.0):\n",
    "        self.scale = scale\n",
    "    \n",
    "    def legend_artist(self, legend, orig_handle, fontsize, handlebox):\n",
    "        x0 = handlebox.xdescent+0.5*handlebox.width\n",
    "        y0 = handlebox.ydescent + 0.5*handlebox.height\n",
    "\n",
    "        # Radius from axis to display and then to handlebox:\n",
    "        R = orig_handle.get_radius()\n",
    "\n",
    "        # Now xy is centered in the axes.\n",
    "        # Get the relative size of y axis interval in point:\n",
    "        xlim = orig_handle.axes.get_xlim()\n",
    "        ylim = orig_handle.axes.get_ylim()\n",
    "        dy_ax_pt = 72*(ax.get_position().y1 - ax.get_position().y0) * fig.get_figheight()\n",
    "\n",
    "        # Rescale to points:\n",
    "        R *= dy_ax_pt / (ylim[1]-ylim[0])\n",
    "        \n",
    "        # Rescale to desired size:\n",
    "        R *= self.scale\n",
    "        \n",
    "        patch = Circle([x0, y0], R,#R_hb,\n",
    "                       facecolor=orig_handle.get_facecolor(),\n",
    "                       edgecolor=orig_handle.get_edgecolor(),\n",
    "                       hatch=orig_handle.get_hatch(),\n",
    "                       linewidth=orig_handle.get_linewidth(),\n",
    "                       transform=handlebox.get_transform()\n",
    "                      )\n",
    "        handlebox.add_artist(patch)\n",
    "        return patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6.975,4.15), dpi=250)\n",
    "\n",
    "# The background axis. Comment the last line to\n",
    "# plot the axis splines which are useful for layouting.\n",
    "ax_bg = fig.add_axes((0,0,1,1))\n",
    "ax_bg.text(0.02, 0.97, '(a)', ha='center', va='center')\n",
    "ax_bg.set_xlim(0,1)\n",
    "ax_bg.set_ylim(0,1)\n",
    "ax_bg.set_axis_off()\n",
    "\n",
    "\n",
    "# Position the local maps:\n",
    "ax_pos = [\n",
    "    (0.00, 0.4, 0.23, 0.6),   # USA\n",
    "    (0.13, 0.2, 0.1, 0.1),   # Western South America \n",
    "    (0.28, 0.38, 0.26, 0.61),    # Europe\n",
    "    (0.52, 0.1, 0.1, 0.15),   # East Africa\n",
    "    (0.68, 0.52, 0.17, 0.17),  # central asia\n",
    "    (0.77, 0.47, 0.3, 0.3),    # China\n",
    "    (0.61, 0.15, 0.24, 0.24),    # India\n",
    "    (0.86, 0.02, 0.15, 0.15),   # Australia\n",
    "    (0.23, 0.02, 0.15, 0.15),   # Eastern South America\n",
    "    (0.51, 0.415, 0.23, 0.31),    # Europe 2\n",
    "    (0.66, 0.85, 0.07, 0.09),    # Siberia\n",
    "]\n",
    "\n",
    "axes = []\n",
    "for i in range(len(proj_strings)):\n",
    "    ax = fig.add_axes(ax_pos[i])\n",
    "    axes.append(ax)\n",
    "\n",
    "    \n",
    "# Plot the local axes:\n",
    "vmin = HEAT.min()\n",
    "vmax = HEAT.max()\n",
    "for i,ps in enumerate(proj_strings):\n",
    "    ax = axes[i]\n",
    "    if i == 4 or i == 10:\n",
    "        ax.add_patch(MPolygon([(xlims[i,0],ylims[i,0]), (xlims[i,1],ylims[i,0]),\n",
    "                           (xlims[i,1],ylims[i,1]), (xlims[i,0],ylims[i,1])],\n",
    "                          color='lightgray', zorder=0))\n",
    "    else:\n",
    "        ax.add_patch(MPolygon([(xlims[i,0],ylims[i,0]), (xlims[i,1],ylims[i,0]),\n",
    "                           (xlims[i,1],ylims[i,1]), (xlims[i,0],ylims[i,1])],\n",
    "                          color='w', zorder=0))\n",
    "    ax.set_xlim(xlims[i])\n",
    "    ax.set_ylim(ylims[i])\n",
    "    mp = Map(ps, ax, xlims[i], ylims[i])\n",
    "    mp.add_data(gshhs_l_1[i], edgecolor='none', facecolor='lightgray')\n",
    "    if len(gcp_xy[i][0]) > 0:\n",
    "        for gxy in zip(*gcp_xy[i]):\n",
    "            h1 = ax.add_patch(Circle(gxy, 80e3, edgecolor='k', facecolor='#eeeeee', linewidth=0.7, zorder=1))\n",
    "\n",
    "    h0 = ax.scatter(X[i], Y[i], c=heat[i], marker='.', edgecolor='none', cmap='inferno',\n",
    "                    vmin=vmin, vmax=vmax, zorder=2, s=10, rasterized=True)\n",
    "    mp.plot_axes(10, fontsize=6)\n",
    "\n",
    "# Axes boundary coordinates:\n",
    "axes_x0_x1_y0_y1 = np.array([(p.x0, p.x1, p.y0, p.y1) for p in [ax.get_position() for ax in axes]])\n",
    "xlim_real = np.array([ax.get_xlim() for ax in axes])\n",
    "ylim_real = np.array([ax.get_ylim() for ax in axes])\n",
    "\n",
    "\n",
    "# Compute the polygons:\n",
    "gshhs_c_xy, lon_grid_diff, lat_grid_diff, xg_rel, yg_rel \\\n",
    "   = project_polygon(gshhs_c_1.multipolygons, axes_x0_x1_y0_y1, xlims, ylims, xlim_real, ylim_real,\n",
    "                     proj_strings, fig.get_figwidth(), fig.get_figheight(),\n",
    "                     -130.0, 170.0, -50.0, 60.0, nx=400, ny=200)\n",
    "\n",
    "\n",
    "# San Andreas polygons:\n",
    "proj = Proj(proj_strings[0])\n",
    "for poly in geometry[\"selection_polygons_lola\"]:\n",
    "    h2 = axes[0].add_patch(MPolygon(np.stack(proj(*poly.T), axis=1), facecolor='none',\n",
    "                                    edgecolor='steelblue'))\n",
    "\n",
    "ax_bg.add_collection(PolyCollection(gshhs_c_xy, color='lightgray'));\n",
    "\n",
    "ax_bg.legend(handles=(h0,h1,h2),\n",
    "             labels=('NGHF','Disks with $R=80\\,\\mathrm{km}$','Investigated regions'),\n",
    "             handler_map = {Circle : CircleHandler()}, fontsize=8)\n",
    "\n",
    "\n",
    "# The heat flow statistics:\n",
    "ax2 = fig.add_axes((0.005, 0.07, 0.156, 0.3))\n",
    "ax2.tick_params(labelsize=6)\n",
    "ax2.tick_params(axis='y', direction='in', pad=-0.5)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_linestyle('--')\n",
    "ax2.set_xlabel('Heat flow ($\\mathrm{mW\\,m}^{-2}$)',\n",
    "               fontsize=6, labelpad=0.0)\n",
    "ax2.set_ylabel('EDF', fontsize=6)\n",
    "ax2.step(np.sort(HEAT), (np.arange(HEAT.size)+1)/HEAT.size, linewidth=0.8)\n",
    "ax2.set_ylim((0,1))\n",
    "ax3 = ax2.twinx()\n",
    "ax3.set_position(ax2.get_position())\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.hist(HEAT, 50, facecolor='pink', histtype='stepfilled')\n",
    "ax2.set_zorder(ax3.get_zorder()+1)\n",
    "ax2.set_facecolor('none')\n",
    "ax2.set_yticks([0.0, 0.5, 1.0])\n",
    "ax2.set_yticklabels(['0%','50%','100%'], va='bottom', ha='left')\n",
    "ax2.text(10, 0.93, '(b)', ha='center', va='center')\n",
    "\n",
    "\n",
    "fig.savefig('figures/04-World-Map.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "> Lucazeau, F. (2019). Analysis and mapping of an updated terrestrial heat\n",
    ">    flow data set. Geochemistry, Geophysics, Geosystems, 20, 4001– 4024.\n",
    ">    https://doi.org/10.1029/2019GC008389\n",
    ">\n",
    "> Wessel, P., and W. H. F. Smith, A Global Self-consistent, Hierarchical,\n",
    ">    High-resolution Shoreline Database, J. Geophys. Res., 101, 8741-8743, 1996\n",
    ">    https://doi.org/10.1029/96JB00104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "```\n",
    "A notebook to plot a global map of the heat flow data and the\n",
    "random global R-disk covering.\n",
    "\n",
    "This file is part of the REHEATFUNQ model.\n",
    "\n",
    "Author: Malte J. Ziebarth (ziebarth@gfz-potsdam.de)\n",
    "\n",
    "Copyright © 2019-2022 Deutsches GeoForschungsZentrum Potsdam,\n",
    "            2022 Malte J. Ziebarth\n",
    "            \n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}