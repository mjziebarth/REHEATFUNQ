{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and Filter the New Global Heat Flow (NGHF) Dataset\n",
    "This notebook loads the heat flow data base in its raw format and filters according to the\n",
    "quality criteria of the REHEATFUNQ model description paper. Accordingly, the NGHF data set\n",
    "(Lucazeau, 2019) is used. If you would like to use a different data set, jump to the\n",
    "[Save the Filtered Data Set](#Save-the-Filtered-Data-Set) section to learn abouit the required\n",
    "format in which the data set needs to be saved.\n",
    "\n",
    "To run this notebook, you need to download the NGHF data set of Lucazeau (2019) first. The necessary file\n",
    "is `2019GC008389-sup-0004-Data_Set_SI-S02.zip` and can be downloaded [here](https://agupubs.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1029%2F2019GC008389&file=2019GC008389-sup-0004-Data_Set_SI-S02.zip). If this\n",
    "link should not work anymore, the data set might be retrievable from the DOI listed below.\n",
    "\n",
    "\n",
    "### Reference:\n",
    "> Lucazeau, F. (2019). Analysis and mapping of an updated terrestrial heat\n",
    ">    flow data set. Geochemistry, Geophysics, Geosystems, 20, 4001– 4024.\n",
    ">    https://doi.org/10.1029/2019GC008389\n",
    "\n",
    "From the ZIP file, you need to extract the `NGHF.csv` table and provide a working path to the file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nghf_file = 'data/NGHF.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General imports used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from plotconfig import *\n",
    "from cmcrameri.cm import *\n",
    "from scipy.special import erf\n",
    "import matplotlib.pyplot as plt\n",
    "from zeal2022hf import get_cm_colors\n",
    "from reheatfunq.data import read_nghf\n",
    "from pdtoolbox import normal_pdf, normal_cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Now we load this data base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nghf_lon, nghf_lat, nghf_hf, nghf_quality, nghf_yr, nghf_type, \\\n",
    "nghf_max_depth, nghf_uncertainty, indexmap \\\n",
    "    = read_nghf(nghf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create NumPy arrays from some numeric data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nghf_lon = np.array(nghf_lon)\n",
    "nghf_lat = np.array(nghf_lat)\n",
    "nghf_hf = np.array(nghf_hf)\n",
    "nghf_yr = np.array(nghf_yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"land:\",np.count_nonzero([n == 'land' for n in nghf_type]))\n",
    "print(\"ocean:\",np.count_nonzero([n == 'ocean' for n in nghf_type]))\n",
    "print(\"land A-C:\",np.count_nonzero([n == 'land' and q in ('A','B','C')\n",
    "                                    for n,q in zip(nghf_type,nghf_quality)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(nghf_yr[nghf_yr < 2030], bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "Here, we choose all heat flow data lying on land. Also, we use only data that has quality of at least C assigned, and use data newer than 1960s (increase in measurement quality, see Lucazeau (2019)). Also we exclude geothermal data points using Lucazeau's empirical limit of $250 \\,\\mathrm{mW}/\\mathrm{m}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only positive heat flow:\n",
    "continental_mask_base = (nghf_hf > 0)\n",
    "\n",
    "# Select only points on land:\n",
    "continental_mask_base &= [n == 'land' for n in nghf_type]\n",
    "\n",
    "# Quality selection: At least 'B' quality:\n",
    "continental_mask_base &= [x in ('A','B') for x in nghf_quality]\n",
    "\n",
    "# Select only data points from years 1990 till now:\n",
    "continental_mask_base &= (nghf_yr <= 2020) & (nghf_yr >= 1990)\n",
    "\n",
    "# Restricted heat flow, using Lucazeau (2019) empirical criterion (restricted to below 250 mW/m^2):\n",
    "continental_mask_capped = (continental_mask_base & (nghf_hf < 250.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_mask = continental_mask_capped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of the Filtered Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final data set size:      \", np.count_nonzero(main_mask))\n",
    "print(\"Minimum heat flow (mW/m²):\", nghf_hf[main_mask].min())\n",
    "print(\"Maximum heat flow (mW/m²):\", nghf_hf[main_mask].max())\n",
    "print(\"Average heat flow (mW/m²):\", nghf_hf[main_mask].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the relative error distribution of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_A = np.array([q == 'A' for q in nghf_quality]) & main_mask & ~np.isinf(np.array(nghf_uncertainty))\n",
    "rel_uncertainty_A = np.array(nghf_uncertainty)[mask_A] / nghf_hf[mask_A]\n",
    "mask_B = np.array([q == 'B' for q in nghf_quality]) & main_mask & ~np.isinf(np.array(nghf_uncertainty))\n",
    "rel_uncertainty_B = np.array(nghf_uncertainty)[mask_B] / nghf_hf[mask_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X00 = 0.08\n",
    "X01 = 0.30\n",
    "X02 = 0.34\n",
    "W0 = 0.39\n",
    "S0 = 0.08\n",
    "S1 = 0.08\n",
    "W1 = 0.3\n",
    "S2 = 0.24\n",
    "W2 = 1 - W0 - W1\n",
    "\n",
    "def mixture_pdf(x):\n",
    "    SQ2 = np.sqrt(2)\n",
    "    norm =   W0 * 0.5 * (1.0 - erf(-X00/(SQ2*S0))) \\\n",
    "           + W1 * 0.5 * (1.0 - erf(-X01/(SQ2*S1))) \\\n",
    "           + W2 * 0.5 * (1.0 - erf(-X02/(SQ2*S2)))\n",
    "    return  (W0 * normal_pdf(xplot, X00, S0)\n",
    "             + W1*normal_pdf(xplot, X01, S1)\n",
    "             + W2*normal_pdf(xplot, X02, S2)) / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KDE of the distribution of relative errors with a normal kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of the KDE:\n",
    "S = 0.06\n",
    "\n",
    "xplot = np.linspace(0, 1.1, 200)\n",
    "\n",
    "WA = 0.0\n",
    "kde_A = np.zeros_like(xplot)\n",
    "for q in rel_uncertainty_A:\n",
    "    kde_A += normal_pdf(xplot, q, S)\n",
    "    WA += 1.0 - normal_cdf(0.0, q, S)\n",
    "kde_A /= WA\n",
    "\n",
    "\n",
    "WB = 0.0\n",
    "kde_B = np.zeros_like(xplot)\n",
    "for q in rel_uncertainty_B:\n",
    "    kde_B += normal_pdf(xplot, q, S)\n",
    "    WB += 1.0 - normal_cdf(0.0, q, S)\n",
    "kde_B /= WB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_cm_colors(vik, 13)\n",
    "color0 = colors[0]\n",
    "color1 = colors[8]\n",
    "color2 = colors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4.0, 2.5))\n",
    "ax = fig.add_axes((0.11, 0.15, 0.53, 0.84))\n",
    "ax.plot(xplot, kde_A, linewidth=1, color=color0, label=\"'A'-quality data\")\n",
    "ax.plot(xplot, kde_B, linewidth=1, color=color1, label=\"'B'-quality data\")\n",
    "ax.plot(xplot, mixture_pdf(xplot), linewidth=1, color=color2,\n",
    "        linestyle='--', label='Mixture')\n",
    "\n",
    "ax.set_xlim((0, 1.1))\n",
    "ax.set_ylim(0, ax.get_ylim()[1])\n",
    "ax.text(0.05, 4.0, '(a)', ha='center', va='center')\n",
    "\n",
    "ax.set_xlabel('Relative uncertainty of HF (given in table)')\n",
    "ax.set_ylabel('Empirical distribution function');\n",
    "\n",
    "(h2,h3,h0), (l2,l3,l0) = ax.get_legend_handles_labels()\n",
    "ax.legend(ncol=1, handles=(h0,h2,h3), labels=(l0,l2,l3));\n",
    "ax = fig.add_axes((0.83, 0.15, 0.15, 0.84))\n",
    "ax.bar((1, 2), (np.count_nonzero(mask_A), np.count_nonzero(mask_B)),\n",
    "       width=0.5, color=(color0, color1))\n",
    "ax.set_xticks((1, 2))\n",
    "ax.set_xticklabels(('A','B'))\n",
    "ax.set_ylabel('Data points with uncertainty specified\\nin filtered data set')\n",
    "ax.set_xlabel('Quality ranking');\n",
    "ax.text(0.93, 307, '(b)', ha='center', va='center')\n",
    "fig.savefig('figures/01-quality-vs-uncertainty.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Filtered Data Set\n",
    "Here, we export the data for further analysis in the other notebooks.\n",
    "\n",
    "Ensure that all directories exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "Path(\"intermediate\").mkdir(exist_ok=True)\n",
    "Path(\"results\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `numpy.save` function to save a tuple `(hf, lon, lat)` to\n",
    "the file `data/heat-flow-selection-mW_m2.npy`. If you wish to perform\n",
    "the analysis of the following notebooks but load heat flow data from\n",
    "another source or use custom data filtering, you could save to that\n",
    "file. Make sure to adhere to the following characteristics:\n",
    " - `hf` should be a NumPy array of shape `(N,)` that lists the heat\n",
    "   flow at the data points in $\\mathrm{mW}/\\mathrm{m}^2$\n",
    " - `lon` should be a NumPy array of shape `(N,)` listing the data\n",
    "   point longitude coordinates in degrees\n",
    " - `lat` should be a NumPy array of shape `(N,)` listing the data\n",
    "   point latitude coordinates in degrees\n",
    " - indices in the three arrays have to refer to the data points\n",
    "   in equal order\n",
    " - all NumPy arrayse should be of double precision data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('intermediate/heat-flow-selection-mW_m2.npy',\n",
    "        (nghf_hf[main_mask], nghf_lon[main_mask], nghf_lat[main_mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a map from the filtered data set indices to indices in the original NGHF data base.\n",
    "\n",
    "The map we save to `export/nghf-selection-indices.csv` contains one column for each data\n",
    "point we saved in `data/heat-flow-selection-mW_m2.npy`. The entry in each column refers\n",
    "to the row in `NGHF.csv` that the data point was read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_indices = np.argwhere(main_mask)\n",
    "final_index_map = [indexmap[int(i)] for i in used_indices]\n",
    "\n",
    "with open('results/nghf-selection-indices.csv','w') as f:\n",
    "    f.write(','.join(str(fi) for fi in final_index_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "```\n",
    "A notebook to read and filter the NGHF data base.\n",
    "\n",
    "This file is part of the REHEATFUNQ model.\n",
    "\n",
    "Author: Malte J. Ziebarth (ziebarth@gfz-potsdam.de)\n",
    "\n",
    "Copyright © 2019-2022 Deutsches GeoForschungsZentrum Potsdam,\n",
    "            2022 Malte J. Ziebarth\n",
    "            \n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}